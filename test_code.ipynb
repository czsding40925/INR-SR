{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28444,"status":"ok","timestamp":1727903382080,"user":{"displayName":"HiDing in the Connor","userId":"07635271360929410303"},"user_tz":420},"id":"RbSH1xUyBlYR","outputId":"2e5a8568-523e-41de-b8d2-90bfa14a133c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Othercomputers/My MacBook Pro/Projects/SR-INR\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/Othercomputers/My MacBook Pro/Projects/SR-INR"]},{"cell_type":"markdown","metadata":{"id":"SmBflcaGDOM-"},"source":["## Train Dense INR\n","For image 1, 10, 15\n","* Iterations: 150000\n","* Layer size (lss): 50\n","* Number of layers: 15 (note these are all larger than the original COIN)\n","* Prune percentage: 40\n","* Refine iteration: 10000\n","* Change ld to results/image_{id}\n","\n","For image 2, 7, 13\n","* Iterations: 50000\n","* Layer size(lss): 28\n","* Number of layers: 8 (original paper parameters)\n","* Prune percentage: 4\n","* Refine Iteration: 2000\n","\n","For image 8, 17, 23\n","Updated training file (train.py), pruning/quantization/surp in separate file\n","* Iterations: 100000\n","* Layer size(lss): 36\n","* Number of layers: 12 (original paper parameters)\n","\n"]},{"cell_type":"code","source":["!python train.py --num_iters 100000 --layer_size 36 --num_layers 12 --image_id 8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXqc4SX55fxi","executionInfo":{"status":"ok","timestamp":1727903101836,"user_tz":420,"elapsed":2294654,"user":{"displayName":"HiDing in the Connor","userId":"07635271360929410303"}},"outputId":"91349baa-81bd-43f1-c355-3b49009b3c20"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","Fitting SIREN to Kodak Image8...\n","Model size: 59.5kB\n","Full precision bpp: 1.21\n","100%|██████████████| 100000/100000 [38:10<00:00, 43.66it/s, best_psnr=21.1, loss=0.00815, psnr=20.9]\n","Best training psnr: 21.08\n"]}]},{"cell_type":"markdown","metadata":{"id":"YJz7USjuRxMd"},"source":["## Successive Refinement\n","* Takes a trained model as input\n","* Outputs a sparse model through the SuRP algorithm\n","* Model Directory: \"./results/image_{iid}/best_model_{iid}.pt\"\n","\n","For large models (50 layer size, 15 layers):\n","* Total iterations: 100000\n","* Save image per 1000 iterations\n","\n","For small models: (28 layer size, 8 layers):\n","* Total iterations: 50000\n","* Save image per 500 iterations."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":192026,"status":"ok","timestamp":1727893437048,"user":{"displayName":"HiDing in the Connor","userId":"07635271360929410303"},"user_tz":420},"id":"wH4uE5E2C7X8","outputId":"6be7fc2e-8220-4cfd-9e9f-192c378a08fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","/content/drive/Othercomputers/My MacBook Pro/Projects/SR-INR/surp.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path)\n","Target network weights:\n","net.0.linear.weight: torch.Size([50, 2])\n","net.0.linear.bias: torch.Size([50])\n","net.1.linear.weight: torch.Size([50, 50])\n","net.1.linear.bias: torch.Size([50])\n","net.2.linear.weight: torch.Size([50, 50])\n","net.2.linear.bias: torch.Size([50])\n","net.3.linear.weight: torch.Size([50, 50])\n","net.3.linear.bias: torch.Size([50])\n","net.4.linear.weight: torch.Size([50, 50])\n","net.4.linear.bias: torch.Size([50])\n","net.5.linear.weight: torch.Size([50, 50])\n","net.5.linear.bias: torch.Size([50])\n","net.6.linear.weight: torch.Size([50, 50])\n","net.6.linear.bias: torch.Size([50])\n","net.7.linear.weight: torch.Size([50, 50])\n","net.7.linear.bias: torch.Size([50])\n","net.8.linear.weight: torch.Size([50, 50])\n","net.8.linear.bias: torch.Size([50])\n","net.9.linear.weight: torch.Size([50, 50])\n","net.9.linear.bias: torch.Size([50])\n","net.10.linear.weight: torch.Size([50, 50])\n","net.10.linear.bias: torch.Size([50])\n","net.11.linear.weight: torch.Size([50, 50])\n","net.11.linear.bias: torch.Size([50])\n","net.12.linear.weight: torch.Size([50, 50])\n","net.12.linear.bias: torch.Size([50])\n","net.13.linear.weight: torch.Size([50, 50])\n","net.13.linear.bias: torch.Size([50])\n","net.14.linear.weight: torch.Size([50, 50])\n","net.14.linear.bias: torch.Size([50])\n","last_layer.linear.weight: torch.Size([3, 50])\n","last_layer.linear.bias: torch.Size([3])\n","Mean of the magnitudes is: 0.017611969262361526\n","Total target network params: 36003\n","\n","100%|███████████████████████████| 100000/100000 [03:05<00:00, 539.61it/s, psnr=33.31, sparsity=0.00]\n","Plot saved at ./results/sr_images/image15/sparsity_psnr_plot.png\n"]}],"source":["!python sr.py -it 100000 -iit 1000 -ld \"./results/image_15/best_model_15.pt\" -iid 15 --layer_size 50 --num_layers 15"]},{"cell_type":"markdown","metadata":{"id":"mSz6_g5g1b7v"},"source":["## Turn images into GIFs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17350,"status":"ok","timestamp":1727893191847,"user":{"displayName":"HiDing in the Connor","userId":"07635271360929410303"},"user_tz":420},"id":"NASVxBDpSMHA","outputId":"0f34b10c-3ecf-405c-f005-e845094a9aaa"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-405e04adbd79>:26: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n","  images.append(imageio.imread(filepath))\n"]},{"output_type":"stream","name":"stdout","text":["GIF saved at results/sr_images/image13/result_animation.gif\n"]}],"source":["import os\n","import imageio\n","\n","def create_gif_from_images(image_folder, output_gif, fps=5):\n","    \"\"\"\n","    Create a GIF from a series of images in a folder.\n","\n","    Args:\n","        image_folder (str): The path to the folder containing images.\n","        output_gif (str): The output path and filename for the GIF.\n","        fps (int): Frames per second (speed of the GIF).\n","    \"\"\"\n","    # Get a sorted list of all images in the directory\n","    image_files = sorted([f for f in os.listdir(image_folder) if f.startswith('test') and f.endswith('.png')],\n","                         key=lambda x: int(x.replace('test', '').replace('.png', '')))\n","\n","    # Check if there are images to process\n","    if not image_files:\n","        print(\"No images found in the directory!\")\n","        return\n","\n","    # Read and store images\n","    images = []\n","    for filename in image_files:\n","        filepath = os.path.join(image_folder, filename)\n","        images.append(imageio.imread(filepath))\n","\n","    # Save images as a GIF\n","    imageio.mimsave(output_gif, images, fps=fps)\n","    print(f\"GIF saved at {output_gif}\")\n","\n","# Path to the image folder and output GIF file (change appropriate folder names)\n","image_folder = \"results/sr_images/image13\"\n","output_gif_path = os.path.join(image_folder, \"result_animation.gif\")\n","\n","# Create the GIF\n","create_gif_from_images(image_folder, output_gif_path, fps=10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dSqTYe51b7v"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## New Model Compression File\n","Allows for running Mag_Pruning/Quantization/SuRP"],"metadata":{"id":"J2BYyyBfEA1E"}},{"cell_type":"markdown","source":["### Quantization"],"metadata":{"id":"o76HAe96EnI1"}},{"cell_type":"code","source":["!python compress.py --image_id 1 --compression_type Quantization --num_layers 15 --layer_size 50 --quant_level half"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOg1kY9-EH-E","executionInfo":{"status":"ok","timestamp":1727903585780,"user_tz":420,"elapsed":4857,"user":{"displayName":"HiDing in the Connor","userId":"07635271360929410303"}},"outputId":"8f08c932-b4fc-4c97-aee6-a879130fe833"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/My MacBook Pro/Projects/SR-INR/compress.py\", line 54, in <module>\n","    compressor = quantization(func_rep, args.image_id, args.compression_type, \n","TypeError: quantization.__init__() takes 2 positional arguments but 7 were given\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qvu9q54XEzVX"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}